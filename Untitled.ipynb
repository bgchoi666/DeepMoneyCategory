{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: 1249999975000000\n",
      "Result: 3749999975000000\n",
      "Result: STOP\n",
      "total: 4999999950000000\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def work(id, start, end, result):\n",
    "    total = 0\n",
    "    for i in range(start, end):\n",
    "        total += i\n",
    "    result.put(total)\n",
    "    return\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    START, END = 0, 100000000\n",
    "    result = Queue()\n",
    "    th1 = Process(target=work, args=(1, START, END//2, result))\n",
    "    th2 = Process(target=work, args=(2, END//2, END, result))\n",
    "    \n",
    "    th1.start()\n",
    "    th2.start()\n",
    "    th1.join()\n",
    "    th2.join()\n",
    "\n",
    "    result.put('STOP')\n",
    "    total = 0\n",
    "    while True:\n",
    "        tmp = result.get()\n",
    "        print(f\"Result: {tmp}\")\n",
    "        if tmp == 'STOP':\n",
    "            break\n",
    "        else:\n",
    "            total += tmp\n",
    "    print(f\"total: {total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import util\n",
    "import preprocess as prepro\n",
    "import models\n",
    "import learn\n",
    "from learn import GenerateResult\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # 텐서플로가 첫 번째 GPU에 1GB 메모리만 할당하도록 제한\n",
    "  try:\n",
    "#    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')    \n",
    "    tf.config.experimental.set_visible_devices(gpus[1], 'GPU')    \n",
    "    #tf.config.experimental.set_virtual_device_configuration(\n",
    "    #    gpus[1],\n",
    "    #    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "  except RuntimeError as e:\n",
    "    # 프로그램 시작시에 가장 장치가 설정되어야만 합니다\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '~/Data/kospi200f_809_0403.csv'\n",
    "item_name = 'kospi200f_reinfo_809'\n",
    "train_start = '2000-01-31'\n",
    "train_end = '2018-12-31'\n",
    "test_start = '2019-01-02'\n",
    "test_end = '2020-04-02'\n",
    "\n",
    "remove_columns = ['date', '종가', '시가', '고가', '저가']\n",
    "target_column = '종가'\n",
    "input_columns = []\n",
    "target_type = 'as_is'\n",
    "\n",
    "model_name = 'ddaeryuble'\n",
    "channel = False\n",
    "\n",
    "trans_day = 10\n",
    "\n",
    "target_alpha = 100\n",
    "future_day = 1\n",
    "n_timestep = 120\n",
    "time_interval = 1\n",
    "input_size = 809\n",
    "n_unit = 800\n",
    "batch_size = 32\n",
    "learning_rate = 0.0005\n",
    "n_iteration = 10000\n",
    "\n",
    "alpha = 0.5\n",
    "beta = 0.1\n",
    "\n",
    "checkpoint_path = model_name + \"/pred\"+str(future_day)+\"_trans\"+str(trans_day)+\".ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = util.read_datafile(file_name)\n",
    "df = dataframe.copy()\n",
    "\n",
    "model1 = models.LSTM(n_timestep,input_size,n_unit,regularizers_alpha=0.01,drop_rate=0.5)\n",
    "model2 = models.DenseLayer(4, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(m1, m2, test_y, test_x):\n",
    "    targets = tf.reshape(test_y[1:, n_timestep-1, 0], [-1])\n",
    "    base_prices = tf.reshape(test_y[:-1, n_timestep-1, 0], [-1])\n",
    "    rates = 1 + (targets - base_prices) / base_prices\n",
    "    updown = tf.math.sign(targets - base_prices)\n",
    "    preds = tf.cast(tf.reshape(m1(test_x, training=False)[:-1, n_timestep-1, 0], [-1]), dtype=tf.float64)\n",
    "\n",
    "    returns = [1.0]\n",
    "    inv_rate = []\n",
    "\n",
    "    n = len(targets)\n",
    "    for i in range(n):\n",
    "\n",
    "        # average_return, std of returns, remaining days, preds[0] \n",
    "        state = []\n",
    "\n",
    "        avg_return = tf.cast(tf.math.reduce_prod(returns)**(1/(i+1)), dtype=tf.float64)\n",
    "        state.append(avg_return)\n",
    "        state.append(tf.math.reduce_std(returns))\n",
    "        state.append((n - i) / n)\n",
    "        state.append(preds[i])\n",
    "        state = np.array(state).reshape((1, 4))\n",
    "\n",
    "        model2_pred = tf.cast(m2(state, training=True)[0, 0], dtype=tf.float64)\n",
    "        #inv_rate.append(model2_pred)\n",
    "        returns.append(tf.math.multiply(tf.convert_to_tensor(rates[i], dtype=tf.float64), model2_pred) + 1-tf.math.abs(model2_pred))\n",
    "        print(\"returns \", returns)\n",
    "\n",
    "    avg_return = tf.math.reduce_prod(returns)**(1/n)\n",
    "    std_return = tf.math.reduce_std(returns)\n",
    "    if std_return == 0: \n",
    "        sharp_ratio = avg_return\n",
    "    else: \n",
    "        sharp_ratio = avg_return / std_return\n",
    "    return -alpha*sharp_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(m1, m2, y, x):\n",
    "    with tf.GradientTape() as tape:\n",
    "        #tape.watch(model2.variables)\n",
    "        loss = loss_fn(m1, m2, y, x)\n",
    "    return tape.gradient(loss, m2.trainable_variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_train_start = df.loc[prepro.date_to_index(df, train_start), 'date']\n",
    "current_train_end = df.loc[prepro.date_to_index(df, train_end), 'date']\n",
    "current_test_start = df.loc[prepro.date_to_index(df, test_start), 'date']\n",
    "current_test_end = df.loc[prepro.date_to_index(df, test_start) + trans_day - 1, 'date']\n",
    "\n",
    "\n",
    "#  각 transfer 구간의 예측값들을 합치기 위하여\n",
    "test_prediction = []\n",
    "test_target = []\n",
    "\n",
    "\n",
    "train_data, test_data = prepro.get_train_test_data(df, target_column, remove_columns, \n",
    "                                                       current_train_start, current_train_end,\n",
    "                                                       current_test_start, current_test_end,\n",
    "                                                       future_day, n_timestep, time_interval)\n",
    "\n",
    "# input_size, columns reset\n",
    "input_size = len(df.columns) - len(remove_columns)\n",
    "input_columns = df.columns.copy()\n",
    "\n",
    "train_x, train_y = prepro.get_LSTM_dataset(train_data, n_timestep, time_interval, input_size, future_day)\n",
    "test_x, test_y = prepro.get_LSTM_dataset(test_data, n_timestep, time_interval, input_size, future_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "returns  [1.0, <tf.Tensor: shape=(), dtype=float64, numpy=0.9200421198919659>]\n",
      "returns  [1.0, <tf.Tensor: shape=(), dtype=float64, numpy=0.9200421198919659>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9998073457805787>]\n",
      "returns  [1.0, <tf.Tensor: shape=(), dtype=float64, numpy=0.9200421198919659>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9998073457805787>, <tf.Tensor: shape=(), dtype=float64, numpy=1.000690770777818>]\n",
      "returns  [1.0, <tf.Tensor: shape=(), dtype=float64, numpy=0.9200421198919659>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9998073457805787>, <tf.Tensor: shape=(), dtype=float64, numpy=1.000690770777818>, <tf.Tensor: shape=(), dtype=float64, numpy=1.002024811552094>]\n",
      "returns  [1.0, <tf.Tensor: shape=(), dtype=float64, numpy=0.9200421198919659>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9998073457805787>, <tf.Tensor: shape=(), dtype=float64, numpy=1.000690770777818>, <tf.Tensor: shape=(), dtype=float64, numpy=1.002024811552094>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9985541330725649>]\n",
      "returns  [1.0, <tf.Tensor: shape=(), dtype=float64, numpy=0.9200421198919659>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9998073457805787>, <tf.Tensor: shape=(), dtype=float64, numpy=1.000690770777818>, <tf.Tensor: shape=(), dtype=float64, numpy=1.002024811552094>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9985541330725649>, <tf.Tensor: shape=(), dtype=float64, numpy=1.0048084786856766>]\n",
      "returns  [1.0, <tf.Tensor: shape=(), dtype=float64, numpy=0.9200421198919659>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9998073457805787>, <tf.Tensor: shape=(), dtype=float64, numpy=1.000690770777818>, <tf.Tensor: shape=(), dtype=float64, numpy=1.002024811552094>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9985541330725649>, <tf.Tensor: shape=(), dtype=float64, numpy=1.0048084786856766>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9997304332525949>]\n",
      "returns  [1.0, <tf.Tensor: shape=(), dtype=float64, numpy=0.9200421198919659>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9998073457805787>, <tf.Tensor: shape=(), dtype=float64, numpy=1.000690770777818>, <tf.Tensor: shape=(), dtype=float64, numpy=1.002024811552094>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9985541330725649>, <tf.Tensor: shape=(), dtype=float64, numpy=1.0048084786856766>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9997304332525949>, <tf.Tensor: shape=(), dtype=float64, numpy=1.0027131149438098>]\n",
      "returns  [1.0, <tf.Tensor: shape=(), dtype=float64, numpy=0.9200421198919659>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9998073457805787>, <tf.Tensor: shape=(), dtype=float64, numpy=1.000690770777818>, <tf.Tensor: shape=(), dtype=float64, numpy=1.002024811552094>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9985541330725649>, <tf.Tensor: shape=(), dtype=float64, numpy=1.0048084786856766>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9997304332525949>, <tf.Tensor: shape=(), dtype=float64, numpy=1.0027131149438098>, <tf.Tensor: shape=(), dtype=float64, numpy=0.9963605872514019>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradients = gradient(model1, model2, test_y, test_x)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "optimizer.apply_gradients(zip(gradients, model2.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow2_p36)",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
